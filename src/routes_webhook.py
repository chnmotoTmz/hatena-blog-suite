"""
LINE Webhook ãƒ«ãƒ¼ãƒˆ - ãƒãƒƒãƒå‡¦ç†å¼·åŒ–ç‰ˆ
å¾“æ¥ç‰ˆã‚’ãƒ™ãƒ¼ã‚¹ã«ãƒãƒƒãƒå‡¦ç†ã¨ãƒ•ã‚©ãƒˆãƒ©ã‚¤ãƒ•çµ±åˆã‚’è¿½åŠ 
"""

from flask import Blueprint, request, abort, jsonify
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, ImageMessage, VideoMessage
from src.services.line_service import LineService
from src.services.gemini_service import GeminiService
from src.services.hatena_service import HatenaService
from src.database import db, Message, Article
from src.config import Config
import os
import json
import threading
import time
from datetime import datetime, timedelta
from collections import defaultdict

import logging
from typing import List, Dict, Any

# ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›è¨­å®šï¼ˆlogs/app.log, INFOä»¥ä¸Š, ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãªã—ï¼‰
if not os.path.exists('logs'):
    os.makedirs('logs')
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/app.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ãƒãƒƒãƒå‡¦ç†ç”¨ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
user_message_buffer = defaultdict(list)  # user_id -> [messages]
user_batch_timers = {}  # user_id -> timer_thread
BATCH_INTERVAL = int(os.getenv('BATCH_INTERVAL_MINUTES', '2')) * 60  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ2åˆ†

webhook_bp = Blueprint('webhook', __name__)

# LINE Bot API ã®åˆæœŸåŒ–
line_bot_api = LineBotApi(Config.LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(Config.LINE_CHANNEL_SECRET)

# ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–
line_service = LineService()
gemini_service = GeminiService()
hatena_service = HatenaService()

# æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ï¼ˆWebæ¤œç´¢æ©Ÿèƒ½ï¼‰
try:
    from src.services.search_service import SearchService
    search_service = SearchService()
    logger.info(f"æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–: {'æœ‰åŠ¹' if search_service.enabled else 'ç„¡åŠ¹'}")
except ImportError:
    search_service = None
    logger.warning("æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")


@webhook_bp.route('/line', methods=['POST'])
def line_webhook():
    """LINE Webhook ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
    logger.info(f"Received webhook request. Headers: {dict(request.headers)}")

    # ç½²åæ¤œè¨¼
    signature = request.headers.get('X-Line-Signature')
    body = request.get_data(as_text=True)

    logger.info(f"Signature: {signature}")
    logger.info(f"Body length: {len(body) if body else 'None'}")
    logger.info(f"Body content: {body[:200] if body else 'None'}")

    # ç½²åãŒå­˜åœ¨ã—ãªã„å ´åˆã®å‡¦ç†
    if not signature:
        logger.error('X-Line-Signature header is missing')
        return jsonify({'error': 'X-Line-Signature header is missing'}), 400

    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ãŒç©ºã®å ´åˆã®å‡¦ç†
    if not body:
        logger.error('Request body is empty')
        return jsonify({'error': 'Request body is empty'}), 400

    try:
        # ä¸€æ™‚çš„ã«ç½²åæ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        logger.warning("DEBUGGING: Skipping signature validation")

        # æ‰‹å‹•ã§ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†
        import json
        webhook_body = json.loads(body)



        # eventsãŒå­˜åœ¨ã—ã€ç©ºã§ãªã„å ´åˆã®ã¿å‡¦ç†
        if 'events' in webhook_body and webhook_body['events']:
            for event_data in webhook_body['events']:
                logger.info(f"Processing event: {event_data}")
                # ã“ã“ã§æ‰‹å‹•ã§ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†
                if event_data.get('type') == 'message':
                    process_message_event_with_batch(event_data)
        else:
            logger.info("No events to process (webhook verification or empty events)")

        logger.info('Webhook handled successfully')
    except Exception as e:
        logger.error(f'Webhook handling error: {str(e)}')
        return jsonify({'error': 'Internal server error'}), 500

    return 'OK'

def process_message_event_with_batch(event_data):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒãƒƒãƒå‡¦ç†å¯¾å¿œã§å‡¦ç†"""
    try:
        message_info = event_data.get('message', {})
        message_type = message_info.get('type')
        user_id = event_data.get('source', {}).get('userId')
        line_message_id = message_info.get('id')
        
        if not user_id or not line_message_id:
            logger.warning("Missing user_id or message_id")
            return
        
        logger.info(f"Processing {message_type} message from {user_id} (batch mode)")
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        message_data = {
            'line_message_id': line_message_id,
            'user_id': user_id,
            'message_type': message_type,
            'timestamp': datetime.now(),
            'processed': False
        }
        
        if message_type == 'text':
            text = message_info.get('text', '')
            message_data['content'] = text
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            message = Message(
                line_message_id=line_message_id,
                user_id=user_id,
                message_type='text',
                content=text
            )
            db.session.add(message)
            db.session.commit()
            
        elif message_type == 'image':
            # ç”»åƒã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ãƒ»ä¿å­˜
            message_content = line_bot_api.get_message_content(line_message_id)
            
            upload_dir = "uploads"
            if not os.path.exists(upload_dir):
                os.makedirs(upload_dir)
            
            image_path = f"{upload_dir}/{line_message_id}.jpg"
            
            with open(image_path, 'wb') as f:
                for chunk in message_content.iter_content():
                    f.write(chunk)
            
            logger.info(f"ç”»åƒä¿å­˜å®Œäº†: {image_path}")
            
            # ã€1å›ç›®Geminiã€‘ç”»åƒã‚’Geminiã§å³åº§ã«è§£æã—ã¦ãƒ†ã‚­ã‚¹ãƒˆåŒ–
            try:
                logger.info(f"Geminiç”»åƒè§£æé–‹å§‹: {image_path}")
                image_analysis = gemini_service.analyze_image(
                    image_path, 
                    "ã“ã®ç”»åƒã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚å†™ã£ã¦ã„ã‚‹ã‚‚ã®ã€å ´æ‰€ã€çŠ¶æ³ã€è‰²å½©ã€é›°å›²æ°—ãªã©ã‚’å…·ä½“çš„ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚"
                )
                
                if image_analysis and image_analysis.strip():
                    analyzed_text = f"ã€ç”»åƒè§£æçµæœã€‘{image_analysis.strip()}"
                    logger.info(f"Geminiç”»åƒè§£ææˆåŠŸ: {len(analyzed_text)}æ–‡å­—")
                else:
                    analyzed_text = "ã€ç”»åƒã€‘ç”»åƒãŒæŠ•ç¨¿ã•ã‚Œã¾ã—ãŸï¼ˆè§£æå¤±æ•—ï¼‰"
                    logger.warning("Geminiç”»åƒè§£æãŒç©ºã®çµæœã‚’è¿”ã—ã¾ã—ãŸ")
                    
            except Exception as e:
                logger.error(f"Geminiç”»åƒè§£æã‚¨ãƒ©ãƒ¼: {e}")
                analyzed_text = "ã€ç”»åƒã€‘ç”»åƒãŒæŠ•ç¨¿ã•ã‚Œã¾ã—ãŸï¼ˆè§£æã‚¨ãƒ©ãƒ¼ï¼‰"
            
            # æ”¹è‰¯ç‰ˆè‡ªä½œMCPã§Imgurã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆOAuthå¯¾å¿œï¼‰
            imgur_url = None
            try:
                import asyncio
                import sys
                sys.path.append('/home/moto/line-gemini-hatena-integration')
                from src.mcp_servers.imgur_server_fastmcp import upload_image
                
                # OAuthèªè¨¼ã§å€‹äººã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                upload_result = asyncio.run(upload_image(
                    image_path=image_path,
                    title=f"LINE_Image_{line_message_id}",
                    description="LINE BotçµŒç”±ç”»åƒï¼ˆå€‹äººã‚¢ã‚«ã‚¦ãƒ³ãƒˆï¼‰",
                    privacy="hidden"  # å€‹äººã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®éå…¬é–‹ç”»åƒ
                ))
                
                if upload_result.get('success'):
                    imgur_url = upload_result.get('url')
                    logger.info(f"Imgur ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {imgur_url}")
                    if os.getenv('IMGUR_ACCESS_TOKEN'):
                        logger.info(f"âœ… å€‹äººã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ç´ä»˜ã‘å®Œäº†: {upload_result.get('imgur_id')}")
                    else:
                        logger.warning("âš ï¸  åŒ¿åã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆIMGUR_ACCESS_TOKENæœªè¨­å®šï¼‰")
                else:
                    logger.error(f"Imgur ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {upload_result.get('error')}")
                    
            except Exception as e:
                logger.error(f"Imgur ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ï¼ˆè§£æçµæœã‚’contentã«ã€Imgur URLã‚‚ä¿å­˜ï¼‰
            message_data['content'] = analyzed_text
            message_data['file_path'] = image_path
            message_data['imgur_url'] = imgur_url
            
            message = Message(
                line_message_id=line_message_id,
                user_id=user_id,
                message_type='image',
                content=analyzed_text,  # è§£æçµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä¿å­˜
                file_path=image_path
            )
            # Imgur URLã‚’è¿½åŠ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ä¿å­˜ï¼ˆå¿…è¦ã«å¿œã˜ã¦DBã‚¹ã‚­ãƒ¼ãƒæ‹¡å¼µï¼‰
            if hasattr(message, 'imgur_url'):
                message.imgur_url = imgur_url
                
            db.session.add(message)
            db.session.commit()
            
        elif message_type == 'video':
            # å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ãƒ»ä¿å­˜
            message_content = line_bot_api.get_message_content(line_message_id)
            
            upload_dir = "uploads"
            if not os.path.exists(upload_dir):
                os.makedirs(upload_dir)
            
            video_path = f"{upload_dir}/{line_message_id}.mp4"
            
            with open(video_path, 'wb') as f:
                for chunk in message_content.iter_content():
                    f.write(chunk)
            
            message_data['content'] = f"Video: {video_path}"
            message_data['file_path'] = video_path
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            message = Message(
                line_message_id=line_message_id,
                user_id=user_id,
                message_type='video',
                content=f"Video: {video_path}",
                file_path=video_path
            )
            db.session.add(message)
            db.session.commit()
        
        else:
            logger.info(f"Unsupported message type: {message_type}")
            return
        
        # ãƒãƒƒãƒã«è¿½åŠ 
        add_message_to_batch(user_id, message_data)
        
    except Exception as e:
        logger.error(f"Error processing message event with batch: {str(e)}")
        import traceback
        traceback.print_exc()

def add_message_to_batch(user_id: str, message_data: Dict[str, Any]):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒãƒƒãƒã«è¿½åŠ ã—ã€ã‚¿ã‚¤ãƒãƒ¼ã‚’è¨­å®š"""
    global user_message_buffer, user_batch_timers
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
    user_message_buffer[user_id].append(message_data)
    logger.info(f"Added message to batch for user {user_id}. Total: {len(user_message_buffer[user_id])}")
    
    # æ—¢å­˜ã®ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
    if user_id in user_batch_timers:
        user_batch_timers[user_id].cancel()
    
    # æ–°ã—ã„ã‚¿ã‚¤ãƒãƒ¼ã‚’è¨­å®š
    timer = threading.Timer(BATCH_INTERVAL, process_user_batch, [user_id])
    timer.start()
    user_batch_timers[user_id] = timer
    
    logger.info(f"Set batch timer for user {user_id} ({BATCH_INTERVAL} seconds)")

def process_user_batch(user_id: str):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒãƒƒãƒã‚’å‡¦ç†ï¼ˆFlask ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œï¼‰"""
    global user_message_buffer, user_batch_timers
    
    try:
        # Flask ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
        from flask import current_app
        from main import create_app
        
        try:
            app = current_app._get_current_object()
        except RuntimeError:
            app = create_app()
        
        with app.app_context():
            if user_id not in user_message_buffer or not user_message_buffer[user_id]:
                logger.info(f"No messages in batch for user {user_id}")
                return
            
            messages = user_message_buffer[user_id].copy()
            
            # ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
            user_message_buffer[user_id] = []
            if user_id in user_batch_timers:
                del user_batch_timers[user_id]
            
            logger.info(f"Processing batch for user {user_id} with {len(messages)} messages")
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¨®é¡åˆ¥ã«åˆ†é¡
            text_messages = [msg for msg in messages if msg['message_type'] == 'text']
            image_messages = [msg for msg in messages if msg['message_type'] == 'image']
            video_messages = [msg for msg in messages if msg['message_type'] == 'video']
            
            # çµ±åˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä½œæˆï¼ˆä¿®æ­£ç‰ˆï¼‰
            title, integrated_content = create_integrated_content_fixed(text_messages, image_messages, video_messages)
            
            if integrated_content and title:
                # ã€ç”»åƒURLæŒ¿å…¥ã€‘æŠ•ç¨¿ç›´å‰ã«Imgur URLã‚’ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§æŒ¿å…¥
                final_content = insert_imgur_urls_to_content(integrated_content, image_messages)
                
                # ã¯ã¦ãªãƒ–ãƒ­ã‚°ã«æŠ•ç¨¿
                article_url = hatena_service.post_article(
                    title=title,
                    content=final_content  # ç”»åƒURLæŒ¿å…¥æ¸ˆã¿ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
                )
                
                if article_url:
                    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é€šçŸ¥
                    content_summary = f"ãƒ†ã‚­ã‚¹ãƒˆ{len(text_messages)}ä»¶ã€ç”»åƒ{len(image_messages)}ä»¶ã€å‹•ç”»{len(video_messages)}ä»¶"
                    line_service.send_message(
                        user_id,
                        f"ğŸ“ çµ±åˆè¨˜äº‹ã‚’æŠ•ç¨¿ã—ã¾ã—ãŸï¼\\n\\nğŸ’« {content_summary}ã‚’çµ„ã¿åˆã‚ã›ã¾ã—ãŸ\\nğŸ”— {article_url}"
                    )
                    
                    # è¨˜äº‹æƒ…å ±ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                    article = Article(
                        title=title,
                        content=final_content,
                        hatena_url=article_url,
                        published=True,
                        status='published'
                    )
                    
                    # ã‚½ãƒ¼ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDã‚’è¨˜éŒ²
                    source_message_ids = [msg['line_message_id'] for msg in messages]
                    article.set_source_messages_list(source_message_ids)
                    
                    # ç”»åƒãƒ‘ã‚¹ã‚’è¨˜éŒ²
                    image_paths = [msg.get('file_path') for msg in image_messages if msg.get('file_path')]
                    if image_paths:
                        article.set_image_paths_list(image_paths)
                    
                    # å‹•ç”»ãƒ‘ã‚¹ï¼ˆæœ€åˆã®ã‚‚ã®ã®ã¿ï¼‰
                    video_paths = [msg.get('file_path') for msg in video_messages if msg.get('file_path')]
                    if video_paths:
                        article.video_path = video_paths[0]
                    
                    db.session.add(article)
                    db.session.commit()
                    
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†æ¸ˆã¿ã«ãƒãƒ¼ã‚¯
                    for msg in messages:
                        db_message = Message.query.filter_by(line_message_id=msg['line_message_id']).first()
                        if db_message:
                            db_message.processed = True
                    db.session.commit()
                    
                    logger.info(f"Batch processing completed for user {user_id}. Article ID: {article.id}")
                else:
                    line_service.send_message(
                        user_id,
                        "âŒ çµ±åˆè¨˜äº‹ã®æŠ•ç¨¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
                    )
            else:
                line_service.send_message(
                    user_id,
                    "âŒ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
                )
                
    except Exception as e:
        logger.error(f"Error processing batch for user {user_id}: {str(e)}")
        import traceback
        traceback.print_exc()
        
        try:
            line_service.send_message(
                user_id,
                f"âŒ ãƒãƒƒãƒå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            )
        except:
            pass

def create_integrated_content_fixed(text_messages: List[Dict], image_messages: List[Dict], video_messages: List[Dict]) -> tuple:
    """çµ±åˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä½œæˆï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã¨æœ¬æ–‡ã‚’åˆ†ã‘ã¦è¿”ã™ï¼‰"""

    try:
        # ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’çµ±åˆ
        all_texts = []
        if text_messages:
            for msg in text_messages:
                all_texts.append(f"ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‘{msg['content']}")
        if image_messages:
            for msg in image_messages:
                if msg.get('content'):
                    all_texts.append(f"ã€ç”»åƒèª¬æ˜ã€‘{msg['content']}")
        if video_messages:
            for msg in video_messages:
                if msg.get('content'):
                    all_texts.append(f"ã€å‹•ç”»èª¬æ˜ã€‘{msg['content']}")

        combined_all_text = '\n'.join(all_texts)

        # ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€
    
        blog_prompt_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'data', 'blog_main_prompt.txt'))
        if not os.path.exists(blog_prompt_path):
            logger.error(f"ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {blog_prompt_path}")
            blog_prompt_template = ""  # ç©ºæ–‡å­—ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        else:
            try:
                with open(blog_prompt_path, 'r', encoding='utf-8') as f:
                    blog_prompt_template = f.read()
            except Exception as e:
                logger.error(f"ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                blog_prompt_template = ""  # ç©ºæ–‡å­—ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å…¥åŠ›æƒ…å ±ã‚’åŸ‹ã‚è¾¼ã‚€
        blog_prompt = blog_prompt_template.replace('{combined_all_text}', combined_all_text)

        # --- Webæ¤œç´¢ã®è‡ªå‹•åˆ¤å®šãƒ»å¼•ç”¨å…ƒãƒªãƒ³ã‚¯ä»˜ä¸ ---
        # 1. ãƒ¡ã‚¤ãƒ³ãƒ†ãƒ¼ãƒã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æŠ½å‡º
        search_queries = extract_search_queries_from_content(combined_all_text)
        logger.info(f"Webæ¤œç´¢è‡ªå‹•åˆ¤å®š: {search_queries}")

        # 2. AIã«Webæ¤œç´¢ã®å¿…è¦æ€§ã‚’åˆ¤å®šã•ã›ã‚‹
        should_search = False
        if search_service and search_queries:
            try:
                search_judge_prompt_template = (
                    "ä»¥ä¸‹ã¯ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ä¸‹æ›¸ãæƒ…å ±ã§ã™ã€‚\n"
                    "ã“ã®å†…å®¹ã‚’èª­è€…ã«ã¨ã£ã¦ååˆ†æœ‰ç›Šãªè¨˜äº‹ã«ã™ã‚‹ã«ã¯ã€Webæ¤œç´¢ã«ã‚ˆã‚‹è¿½åŠ æƒ…å ±ï¼ˆä¾‹ï¼šå…¬å¼æƒ…å ±ã€æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã€ç¬¬ä¸‰è€…ã®è©•ä¾¡ãªã©ï¼‰ãŒå¿…è¦ã§ã™ã‹ï¼Ÿ\n"
                    "\nã€è¨˜äº‹ä¸‹æ›¸ãã€‘\n"
                    "{combined_all_text}\n"
                    "---\n"
                    "å¿…è¦ãªå ´åˆã¯Yesã€ä¸è¦ãªã‚‰Noã¨ã ã‘1è¡Œã§ç­”ãˆã¦ãã ã•ã„ã€‚"
                )
                search_judge_prompt = search_judge_prompt_template.replace('{combined_all_text}', combined_all_text)
                judge_result = gemini_service.generate_content(search_judge_prompt)
                logger.info(f"Webæ¤œç´¢è¦å¦AIåˆ¤å®š: {judge_result}")
                if judge_result and judge_result.strip().lower().startswith('y'):
                    should_search = True
            except Exception as e:
                logger.error(f"Webæ¤œç´¢è¦å¦åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")

        basic_content = gemini_service.generate_content(blog_prompt)
        enhanced_content = basic_content
        source_links = []
        if should_search:
            try:
                # ãƒ¡ã‚½ãƒƒãƒ‰åã‚’ç¢ºèªã—ã€ãªã‘ã‚Œã°ä»®ã§search_and_enhance_contentã«å¤‰æ›´
                if hasattr(search_service, 'enhance_content_with_search_and_links'):
                    enhanced_content, links = search_service.enhance_content_with_search_and_links(
                        basic_content, search_queries
                    )
                elif hasattr(search_service, 'search_and_enhance_content'):
                    enhanced_content, links = search_service.search_and_enhance_content(
                        basic_content, search_queries
                    )
                elif hasattr(search_service, 'enhance_content'):
                    enhanced_content, links = search_service.enhance_content(
                        basic_content, search_queries
                    )
                else:
                    logger.error("SearchServiceã«Webæ¤œç´¢å¼·åŒ–ç”¨ã®ãƒ¡ã‚½ãƒƒãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    enhanced_content, links = basic_content, []
                logger.info(f"Webæ¤œç´¢å¼·åŒ–ãƒ»å¼•ç”¨å…ƒå–å¾—: {links}")
                source_links = links
            except Exception as e:
                logger.error(f"Webæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")

        # 3. è¨˜äº‹æœ«å°¾ã«å¼•ç”¨å…ƒãƒªãƒ³ã‚¯ã‚’å¿…ãšè¿½åŠ 
        if source_links:
            links_section = '\n\n---\n\nå‚è€ƒãƒ»å¼•ç”¨å…ƒ:\n' + '\n'.join(f'- {url}' for url in source_links)
            enhanced_content = f"{enhanced_content}{links_section}"

        integrated_content = enhanced_content

        # ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º: æœ¬æ–‡ä¸­ã®ä¸€ç•ªå°è±¡çš„ãªè¦‹å‡ºã—ï¼ˆMarkdownè¦‹å‡ºã— or å¤ªå­— or ã‚¿ã‚¤ãƒˆãƒ«:ï¼‰ã‚’å„ªå…ˆ
        import re
        title = None
        content = integrated_content

        # 1. <p>ã‚¿ã‚¤ãƒˆãƒ«: ...</p> å½¢å¼ã‚„ ã‚¿ã‚¤ãƒˆãƒ«: ... ã§å§‹ã¾ã‚‹å ´åˆ
        m = re.match(r'<p>\s*ã‚¿ã‚¤ãƒˆãƒ«[:ï¼š]\s*(.+?)</p>', integrated_content)
        if m:
            title = m.group(1).strip()
            content = re.sub(r'<p>\s*ã‚¿ã‚¤ãƒˆãƒ«[:ï¼š].+?</p>\s*', '', integrated_content, count=1).lstrip('\n').strip()
        else:
            m2 = re.match(r'ã‚¿ã‚¤ãƒˆãƒ«[:ï¼š]\s*(.+)', integrated_content)
            if m2:
                title = m2.group(1).strip()
                content = re.sub(r'ã‚¿ã‚¤ãƒˆãƒ«[:ï¼š].+\n?', '', integrated_content, count=1).lstrip('\n').strip()
            else:
                # 2. Markdownè¦‹å‡ºã—ï¼ˆ##, ###, #ï¼‰ã‚’æ¢ã™
                headings = re.findall(r'^(#+)\s*(.+)', integrated_content, re.MULTILINE)
                if headings:
                    title = headings[0][1].strip()
                    content = integrated_content.replace(headings[0][0] + ' ' + title, '', 1).lstrip('\n').strip()
                else:
                    # 3. å¤ªå­—ï¼ˆ**ã‚¿ã‚¤ãƒˆãƒ«**ï¼‰ã‚’æ¢ã™
                    bolds = re.findall(r'\*\*(.+?)\*\*', integrated_content)
                    if bolds:
                        title = bolds[0].strip()
                        content = integrated_content.replace('**' + title + '**', '', 1).lstrip('\n').strip()
                    else:
                        # 4. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ˆé ­è¡Œ
                        first_line = integrated_content.split('\n', 1)[0].strip()
                        title = re.sub(r'[\s\u200b\u3000\uFFFD]+', '', first_line)
                        content = integrated_content[len(first_line):].lstrip('\n').strip()

        # å¤‰ãªæ–‡å­—ï¼ˆã‚¼ãƒ­å¹…ã‚¹ãƒšãƒ¼ã‚¹ã€å…¨è§’ç©ºç™½ã€åˆ¶å¾¡æ–‡å­—ãªã©ï¼‰ã‚’é™¤å»
        title = re.sub(r'[\u200b\u3000\uFFFD]+', '', title)
        content = re.sub(r'[\u200b\u3000\uFFFD]+', '', content)

        logger.info(f"æŠ½å‡ºã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«: {title}")
        # --- ã“ã“ã‹ã‚‰ç”»åƒã®HTMLã‚¿ã‚°ã‚’æœ«å°¾ã«è¿½åŠ  ---
        if image_messages:
            image_html_tags = []
            def is_valid_imgur_url(url):
                import re
                if not url:
                    return False
                if not url.startswith('https://'):
                    return False
                if 'imgur.com' not in url:
                    return False
                if not re.search(r'\.(jpg|jpeg|png|gif)$', url, re.IGNORECASE):
                    return False
                return True

            for i, img_msg in enumerate(image_messages, 1):
                imgur_url = img_msg.get('imgur_url')
                if is_valid_imgur_url(imgur_url):
                    html_tag = f'<p><img src="{imgur_url}" alt="ç”»åƒ{i}" style="max-width: 80%; height: auto; display: block; margin: 20px auto; border: 1px solid #ddd; border-radius: 8px;"></p>'
                    image_html_tags.append(html_tag)
                else:
                    logger.warning(f"ç”»åƒURLãŒç„¡åŠ¹ã¾ãŸã¯éæ¨å¥¨: {imgur_url}")
            if image_html_tags:
                content += "\n\n" + "\n".join(image_html_tags)
        # --- ã“ã“ã¾ã§ç”»åƒæœ«å°¾è¿½åŠ  ---
        logger.info(f"æŠ½å‡ºã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«: {title}")
        return title, content

    except Exception as e:
        logger.error(f"çµ±åˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None, None

def insert_imgur_urls_to_content(content: str, image_messages: List[Dict]) -> str:
    '''ãƒ–ãƒ­ã‚°è¨˜äº‹ã«Imgur URLã‚’ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§æŒ¿å…¥'''
    import re
    try:
        if not image_messages:
            return content

        logger.info(f"ç”»åƒURLæŒ¿å…¥é–‹å§‹: {len(image_messages)}æšã®ç”»åƒ")

        # ç”»åƒURLã‚’åé›†ã—ã€æœ¬æ–‡æœ«å°¾ã«ã¾ã¨ã‚ã¦åŸ‹ã‚è¾¼ã‚€
        # ç”»åƒèª¬æ˜æ–‡ã®ç›´å¾Œã«ç”»åƒã‚¿ã‚°ã‚’æŒ¿å…¥ã€‚ãªã‘ã‚Œã°æœ«å°¾ã«ã¾ã¨ã‚ã¦è¿½åŠ ã€‚
        import re
        new_content = content
        used_urls = set()
        image_html_tags = []
        # ç”»åƒèª¬æ˜æ–‡ã¨URLã®ãƒšã‚¢ã‚’ä½œæˆ
        imgur_pairs = []
        unmatched_urls = []
        for img_msg in image_messages:
            imgur_url = img_msg.get('imgur_url')
            desc = img_msg.get('content')
            if imgur_url:
                if desc and desc.strip():
                    imgur_pairs.append((desc.strip(), imgur_url))
                else:
                    unmatched_urls.append(imgur_url)
                logger.info(f"æŒ¿å…¥äºˆå®šURL: {imgur_url}")

        # æœ¬æ–‡ä¸­ã®ç”»åƒèª¬æ˜æ–‡ã®ç›´å¾Œã«ç”»åƒã‚¿ã‚°ã‚’æŒ¿å…¥ï¼ˆæœ€åˆã®ä¸€è‡´ã®ã¿ï¼‰
        for i, (desc, url) in enumerate(imgur_pairs, 1):
            html_tag = f'<p><img src="{url}" alt="ç”»åƒ{i}" style="max-width: 80%; height: auto; display: block; margin: 20px auto; border: 1px solid #ddd; border-radius: 8px;"></p>'
            pattern = re.escape(desc)
            if url in used_urls:
                continue
            new_content, count = re.subn(pattern, desc + '\n' + html_tag, new_content, count=1)
            if count > 0:
                used_urls.add(url)

        # èª¬æ˜æ–‡ã«ç´ã¥ã‹ãªã„ç”»åƒã¯æœ«å°¾ã«ã¾ã¨ã‚ã¦æŒ¿å…¥
        if unmatched_urls:
            for i, url in enumerate(unmatched_urls, 1):
                html_tag = f'<p><img src="{url}" alt="ç”»åƒ(æœ«å°¾){i}" style="max-width: 80%; height: auto; display: block; margin: 20px auto; border: 1px solid #ddd; border-radius: 8px;"></p>'
                image_html_tags.append(html_tag)
            new_content += "\n\n" + "\n".join(image_html_tags)

        logger.info(f"ç”»åƒURLæŒ¿å…¥å®Œäº†: {len(image_messages)}æšæŒ¿å…¥, æœ€çµ‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚µã‚¤ã‚º: {len(new_content)}æ–‡å­—")
        return new_content

    except Exception as e:
        logger.error(f"ç”»åƒURLæŒ¿å…¥ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return content  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¿”ã™

def extract_fallback_queries(content: str) -> List[str]:
    '''Geminiç­‰ãŒå¤±æ•—ã—ãŸå ´åˆã®ç°¡æ˜“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯'''
    import re
    # ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠãƒ»æ¼¢å­—ãƒ»è‹±æ•°å­—ã®å˜èªã‚’æŠ½å‡º
    words = re.findall(r'[\w\u3040-\u30ff\u4e00-\u9fff]{2,}', content)
    # é »å‡ºä¸Šä½3ä»¶ã‚’è¿”ã™
    from collections import Counter
    common = [w for w, _ in Counter(words).most_common(3)]
    return common

def extract_search_queries_from_content(content: str) -> List[str]:
    '''ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰Webæ¤œç´¢ç”¨ã®ã‚¯ã‚¨ãƒªã‚’AIã§å‹•çš„ã«æŠ½å‡º'''
    try:
        # RAGã§ã‚¸ãƒ£ãƒ³ãƒ«ç‰¹åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        rag_prompt = None
        try:
            import sys
            sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
            from src.rag import predict_with_model
            query_text = content[:100]
            rag_results = predict_with_model(query_text, 'genre_prompts', top_n=1)
            if rag_results and len(rag_results) > 0:
                rag_prompt = rag_results[0]['text']
                logger.info(f"RAGæŠ½å‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {rag_prompt[:60]}...")
        except Exception as e:
            logger.error(f"RAGãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")

        # Geminiã§æ¤œç´¢ã‚¯ã‚¨ãƒªæŠ½å‡º
        extraction_prompt_template = (
            "{rag_prompt}\n"
            "ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ†æã—ã¦ã€èª­è€…ã«ã¨ã£ã¦æœ‰ç›Šãªè¿½åŠ æƒ…å ±ã‚’å¾—ã‚‹ãŸã‚ã®Webæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’3ã¤ã¾ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚\n"
            "\nã‚³ãƒ³ãƒ†ãƒ³ãƒ„:\n"
            "{content}\n"
            "\nå‡ºåŠ›å½¢å¼:\n"
            "æ¤œç´¢ã‚¯ã‚¨ãƒª1\n"
            "æ¤œç´¢ã‚¯ã‚¨ãƒª2\n"
            "æ¤œç´¢ã‚¯ã‚¨ãƒª3\n"
            "\nâ€»å„ã‚¯ã‚¨ãƒªã¯30æ–‡å­—ä»¥å†…ã§ã€æ¤œç´¢ã—ã‚„ã™ã„å½¢ã«ã—ã¦ãã ã•ã„\n"
            "â€»é–¢é€£æ€§ã®é«˜ã„é †ã«ä¸¦ã¹ã¦ãã ã•ã„\n"
            "â€»ã‚¯ã‚¨ãƒªãŒ3ã¤æœªæº€ã®å ´åˆã¯ã€ãã®åˆ†ã ã‘å‡ºåŠ›ã—ã¦ãã ã•ã„"
        )
        extraction_prompt = extraction_prompt_template.replace('{rag_prompt}', rag_prompt if rag_prompt else '').replace('{content}', content)
        queries = []
        try:
            logger.info("Geminiã«ã‚ˆã‚‹æ¤œç´¢ã‚¯ã‚¨ãƒªæŠ½å‡ºã‚’é–‹å§‹")
            extraction_result = gemini_service.generate_content(extraction_prompt)
            if extraction_result and extraction_result.strip():
                lines = extraction_result.strip().split('\n')
                import re
                for line in lines:
                    line = line.strip()
                    # HTMLã‚¿ã‚°é™¤å»
                    line = re.sub(r'<.*?>', '', line)
                    clean_line = re.sub(r'^[\d\.\-\*\+]?\s*', '', line)
                    clean_line = re.sub(r'^[ã€Œã€]|[ã€ã€]$', '', clean_line)
                    if clean_line and len(clean_line) > 3 and len(clean_line) <= 50:
                        queries.append(clean_line)
        except Exception as e:
            logger.error(f"Geminiæ¤œç´¢ã‚¯ã‚¨ãƒªæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        if queries:
            final_queries = queries[:3]
            logger.info(f"GeminiæŠ½å‡ºã‚¯ã‚¨ãƒª: {final_queries}")
            return final_queries
        else:
            # GeminiãŒå¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            logger.info("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šåŸºæœ¬ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã‚’å®Ÿè¡Œ")
            return extract_fallback_queries(content)
    except Exception as e:
        logger.error(f"æ¤œç´¢ã‚¯ã‚¨ãƒªæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return []

# ãƒãƒƒãƒå‡¦ç†çŠ¶æ³ç¢ºèªç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
